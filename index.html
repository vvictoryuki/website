<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jiwen Yu</title>
  
  <meta name="author" content="Jiwen Yu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="images/icon_jiwen.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jiwen Yu</name>
              </p>
		<p>I will be enrolling the Department of Electrical and Electronic Engineering at the University of Hong Kong as a PhD student in 2024 fall, supervised by Prof. <a href="https://xh-liu.github.io/">Xihui Liu</a> at HKU-<a href="https://mmlab.ie.cuhk.edu.hk/">MMLab</a>. I will be working on research topics related to Computer Vision and Embodied AI. Prior to this, I obtained my master's degree from Peking University, where I was advised by Prof. <a href="https://jianzhang.tech/">Jian Zhang</a>.</p>
              <p style="text-align:center">
                <a href="yujiwen@stu.pku.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=uoRPLHIAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/vvictoryuki/">Github</a> &nbsp/&nbsp
		<a href="JiwenYu_CV__latest_24_4_8_.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/jiwen_head_20240311.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/jiwen_head_1114.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


<tr onmouseout="fatezero_stop()" onmouseover="fatezero_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='fatezero_image'><video  width=100% muted autoplay loop>
            <source src="images/7.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <!-- <div class="two" id='fatezero_image_input'> -->
            <video  width=100% muted autoplay loop>
              <source src="images/9.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video>
            <!-- </div> -->
          </div>
          <script type="text/javascript">
            function fatezero_start() {
              document.getElementById('fatezero_image').style.opacity = "1";
            }

            function fatezero_stop() {
              document.getElementById('fatezero_image').style.opacity = "0";
            }
            fatezero_stop()
          </script>
        </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://vvictoryuki.github.io/animatezero.github.io/">
                <papertitle>AnimateZero: Video Diffusion Models are Zero-Shot Image Animators</papertitle>
              </a>
              <br>
		<strong>Jiwen Yu</strong>,
              <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a>,
		<a href="https://chenyangqiqi.github.io/">Chenyang Qi</a>,
		    <a href="https://yzhang2016.github.io/">Yong Zhang</a>,
		    <a href="https://xinntao.github.io/">Xintao Wang</a>,
		    <a href="https://scholar.google.com/citations?hl=zh-CN&user=4oXBp9UAAAAJ">Ying Shan</a>,
              <a href="https://jianzhang.tech/">Jian Zhang</a>
              <br>
	      <em>ArXiv</em>, 2023 
	      <br>
              <a href="https://github.com/vvictoryuki/AnimateZero">code</a> /
              <a href="https://arxiv.org/abs/2312.03793">arXiv</a> /
		<a href="https://github.com/vvictoryuki/AnimateZero/blob/main/AnimateZero.pdf">paper</a> /
		    <a href="https://vvictoryuki.github.io/animatezero.github.io/">project page</a>
              <p></p>
              <p>
		We propose AnimateZero, a zero-shot approach for image animation on generated images. AnimateZero also supports various applications, such as video editing, frame interpolation, real image animation, and more.
              </p>
            </td>
          </tr>	
				

<tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='samurai_image'>
                  <img src='images/cross_a.png' width="160"></div>
                <img src='images/cross_b.png' width="160">
              </div>
              <script type="text/javascript">
                function samurai_start() {
                  document.getElementById('samurai_image').style.opacity = "1";
                }

                function samurai_stop() {
                  document.getElementById('samurai_image').style.opacity = "0";
                }
                samurai_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2305.16936">
                <papertitle>CRoSS: Diffusion Model Makes Controllable, Robust and Secure Image Steganography</papertitle>
              </a>
              <br>
		<strong>Jiwen Yu</strong>,
              <a href="https://villa.jianzhang.tech/people/xuanyu-zhang-%E5%BC%A0%E8%BD%A9%E5%AE%87/">Xuanyu Zhang</a>, 
		    <a href="https://zirconium2159.github.io/">Youmin Xu</a>, 
              <a href="https://jianzhang.tech/">Jian Zhang</a>
              <br>
	      <em>NeurIPS</em>, 2023 
	      <br>
              <a href="https://github.com/vvictoryuki/CRoSS">code</a> /
              <a href="https://arxiv.org/abs/2305.16936">arXiv</a>
              <p></p>
              <p>
		We propose a novel diffusion-based image steganography framework named Controllable, Robust, and Secure Image Steganography (CRoSS). This framework offers significant advantages in controllability, robustness, and security compared to cover-based image steganography methods. Importantly, these benefits are achieved without requiring additional training.
              </p>
            </td>
          </tr>	
    
	<tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='samurai_image'>
                  <img src='images/freedom_a.png' width="160"></div>
                <img src='images/freedom_b.png' width="160">
              </div>
              <script type="text/javascript">
                function samurai_start() {
                  document.getElementById('samurai_image').style.opacity = "1";
                }

                function samurai_stop() {
                  document.getElementById('samurai_image').style.opacity = "0";
                }
                samurai_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2303.09833">
                <papertitle>FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model</papertitle>
              </a>
              <br>
		<strong>Jiwen Yu</strong>,
              <a href="https://wyhuai.github.io/info/">Yinhuai Wang</a>, 
              <a href="https://scholar.google.com/citations?user=dUWdX5EAAAAJ">Chen Zhao</a>, 
		    <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>,
              <a href="https://jianzhang.tech/">Jian Zhang</a>
              <br>
	      <em>ICCV</em>, 2023 
	      <br>
              <a href="https://github.com/vvictoryuki/FreeDoM">code</a> /
              <a href="https://arxiv.org/abs/2303.09833">arXiv</a>
              <p></p>
              <p>
		FreeDoM is a simple but effective training-free method generating results under control from various conditions using unconditional diffusion models.
              </p>
            </td>
          </tr>	

    

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dreamfusion_image'>
                <img src='images/ddnm_after.png' width="160"></div>
                <img src='images/ddnm_before.png' width="160">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://wyhuai.github.io/ddnm.io/">
                <papertitle>Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model</papertitle>
              </a>
              <br>
              <a href="https://wyhuai.github.io/info/">Yinhuai Wang*</a>,
              <strong>Jiwen Yu*</strong>,
							<a href="https://jianzhang.tech/">Jian Zhang</a> (*denotes equal contribution)
              <br>
              <em>ICLR</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://wyhuai.github.io/ddnm.io/">project page</a>
              /
              <a href="https://arxiv.org/pdf/2212.00490.pdf">arXiv</a>
              /
              <a href="https://github.com/wyhuai/DDNM">code</a>
              <p></p>
              <p>
              We bring Range-Null space Decomposition (RND) into diffusion models, enabling diverse image restoration tasks in a zero-shot manner, without extra training or optimization.
              </p>
            </td>
          </tr>

          
          

<!--           <tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='samurai_image'>
                  <img src='images/rnd_after.jpg' width="160"></div>
                <img src='images/rnd_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function samurai_start() {
                  document.getElementById('samurai_image').style.opacity = "1";
                }

                function samurai_stop() {
                  document.getElementById('samurai_image').style.opacity = "0";
                }
                samurai_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2211.13524">
                <papertitle>GAN Prior based Null-Space Learning for Consistent Super-Resolution</papertitle>
              </a>
              <br>
              <a href="https://wyhuai.github.io/info/">Yinhuai Wang</a>, 
              <a href="https://villa.jianzhang.tech/people/yujie-hu-%E8%83%A1%E5%A6%A4%E5%A9%95/">Yujie Hu</a>, 
              <strong>Jiwen Yu</strong>,
              <a href="https://jianzhang.tech/">Jian Zhang</a>
              <br>
	      <em>AAAI</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
	      <br>
              <a href="https://github.com/wyhuai/RND">code</a> /
              <a href="https://arxiv.org/abs/2211.13524">arXiv</a>
              <p></p>
              <p>
		We bring Range-Null space Decomposition (RND) into GAN-Prior based SR models to accelerate the convergence and ensure the downsampling consistency.
              </p>
            </td>
          </tr>	 -->

          

          

        </tbody></table>

				
       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Experience</heading>              
            </td>
		  
		  <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                      <div class="one">
                      <img src="images/tencent.png" width="180">
                      </div>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:top">
                      <papertitle>Research Intern, Tencent AI Lab</papertitle>
                      <br> April, 2023 - January, 2024
                  </td>
                <tr>
            
          </tr>
        </tbody></table>
          
					

          
					
					

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:middle;font-size:small;">
                This cool template is stolen from <a href="https://jonbarron.info/">Jon Barron</a>!
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
